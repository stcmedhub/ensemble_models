{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (\n",
    "    HueSaturationValue, RGBShift, Blur, RandomRotate90, RandomFog, \n",
    "    RandomRain, RandomSnow, Spatter, GaussNoise, CLAHE, CoarseDropout, \n",
    "    MedianBlur, GaussianBlur, PixelDropout\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, Callback\n",
    "from tensorflow.keras.metrics import (\n",
    "    AUC, Precision, Recall, TruePositives, \n",
    "    TrueNegatives, FalsePositives, FalseNegatives\n",
    ")\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation definitions using Albumentations library\n",
    "# Each augmentation is described briefly for better understanding. \n",
    "\n",
    "# 1. Randomly rotate the image by 90 degrees\n",
    "rotate_aug = RandomRotate90(\n",
    "    always_apply=True, \n",
    "    p=1.0\n",
    ")\n",
    "\n",
    "# 2. Adjust hue, saturation, and value with specified limits\n",
    "hue_sat_val = HueSaturationValue(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    hue_shift_limit=(0, 0), \n",
    "    sat_shift_limit=(-5, 20), \n",
    "    val_shift_limit=(-5, 10)\n",
    ")\n",
    "\n",
    "# 3. Apply a blur effect with a specified blur limit\n",
    "blur_aug = Blur(\n",
    "    blur_limit=(3, 7), \n",
    "    p=1.0\n",
    ")\n",
    "\n",
    "# 4. Add fog with adjustable coefficients\n",
    "fog = RandomFog(\n",
    "    fog_coef_lower=0.1, \n",
    "    fog_coef_upper=0.4, \n",
    "    alpha_coef=0.5, \n",
    "    always_apply=False, \n",
    "    p=1.0\n",
    ")\n",
    "\n",
    "# 5. Simulate rain with configurable properties\n",
    "random_rain = RandomRain(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    slant_lower=-5, \n",
    "    slant_upper=5, \n",
    "    drop_length=20, \n",
    "    drop_width=1, \n",
    "    drop_color=(0, 0, 0), \n",
    "    blur_value=3, \n",
    "    brightness_coefficient=1.0, \n",
    "    rain_type='drizzle'\n",
    ")\n",
    "\n",
    "# 6. Simulate snowfall with adjustable intensity and brightness\n",
    "random_snow = RandomSnow(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    snow_point_lower=0.1, \n",
    "    snow_point_upper=0.25, \n",
    "    brightness_coeff=1.2\n",
    ")\n",
    "\n",
    "# 7. Apply spatter effects, useful for simulating dirt or water droplets\n",
    "splatter = Spatter(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    mean=(0.46, 0.46), \n",
    "    std=(2.3, 2.3), \n",
    "    gauss_sigma=(0.99, 0.99), \n",
    "    intensity=(0.2, 0.2), \n",
    "    cutout_threshold=(-0.39, -0.39), \n",
    "    mode=['rain']\n",
    ")\n",
    "\n",
    "# 8. Add Gaussian noise to the image\n",
    "gaus_noise = GaussNoise(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    var_limit=(10.0, 100.0), \n",
    "    per_channel=True, \n",
    "    mean=0.0\n",
    ")\n",
    "\n",
    "# 9. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) for better contrast\n",
    "clahe = CLAHE(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    clip_limit=(1, 5), \n",
    "    tile_grid_size=(10, 10)\n",
    ")\n",
    "\n",
    "# 10. Randomly drop regions of the image (CoarseDropout)\n",
    "coarse_dropout = CoarseDropout(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    max_holes=30, \n",
    "    max_height=10, \n",
    "    max_width=10, \n",
    "    min_holes=10, \n",
    "    min_height=8, \n",
    "    min_width=8, \n",
    "    fill_value=(0, 0, 0), \n",
    "    mask_fill_value=None\n",
    ")\n",
    "\n",
    "# 11. Apply median blur with a specified blur limit\n",
    "median_blur = MedianBlur(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    blur_limit=(3, 7)\n",
    ")\n",
    "\n",
    "# 12. Apply Gaussian blur with adjustable sigma and blur limits\n",
    "gaussian_blur = GaussianBlur(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    blur_limit=(3, 7), \n",
    "    sigma_limit=(0.0, 0.0)\n",
    ")\n",
    "\n",
    "# 13. Randomly drop pixels (PixelDropout) for regularization\n",
    "pixel_dropout = PixelDropout(\n",
    "    always_apply=False, \n",
    "    p=1.0, \n",
    "    dropout_prob=0.05, \n",
    "    per_channel=1, \n",
    "    drop_value=(0, 0, 0), \n",
    "    mask_drop_value=None\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input_augment(x0):\n",
    "    \"\"\"\n",
    "    Applies random augmentations to the input image after being processed \n",
    "    by the Keras ImageDataGenerator.\n",
    "\n",
    "    Args:\n",
    "        x0 (numpy.ndarray): The input image array.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The augmented image.\n",
    "    \"\"\"\n",
    "    # Convert the image to uint8 format\n",
    "    x0 = np.uint8(x0)\n",
    "\n",
    "    # Apply a random 90-degree rotation\n",
    "    x0 = rotate_aug(image=x0)['image']\n",
    "\n",
    "    # Generate a random number to determine augmentation\n",
    "    randomnr = random.randrange(18)\n",
    "\n",
    "    # Apply augmentations based on the random number\n",
    "    if randomnr in [0, 1, 3]:  # No augmentation\n",
    "        pass\n",
    "    elif randomnr == 4:  # Increase color saturation (RGB)\n",
    "        image = Image.fromarray(x0)\n",
    "        enhance_filter = ImageEnhance.Color(image)\n",
    "        enhanced_image = enhance_filter.enhance(2)  # Factor of 2 for saturation\n",
    "        x0 = np.asarray(enhanced_image, dtype=np.uint8)\n",
    "    elif randomnr == 5:  # Adjust hue, saturation, and value\n",
    "        x0 = hue_sat_val(image=x0)['image']\n",
    "    elif randomnr == 6:  # Apply blur\n",
    "        x0 = blur_aug(image=x0)['image']\n",
    "    elif randomnr == 7:  # Add fog\n",
    "        x0 = fog(image=x0)['image']\n",
    "    elif randomnr == 8:  # Simulate rain\n",
    "        x0 = random_rain(image=x0)['image']\n",
    "    elif randomnr == 9:  # Simulate snow\n",
    "        x0 = random_snow(image=x0)['image']\n",
    "    elif randomnr == 10:  # Apply spatter effect\n",
    "        x0 = splatter(image=x0)['image']\n",
    "    elif randomnr == 11:  # Add Gaussian noise\n",
    "        x0 = gaus_noise(image=x0)['image']\n",
    "    elif randomnr == 12:  # Apply CLAHE (contrast enhancement)\n",
    "        x0 = clahe(image=x0)['image']\n",
    "    elif randomnr == 13:  # Apply coarse dropout\n",
    "        x0 = coarse_dropout(image=x0)['image']\n",
    "    elif randomnr == 14:  # Apply CLAHE again (redundant but kept)\n",
    "        x0 = clahe(image=x0)['image']\n",
    "    elif randomnr == 15:  # Apply median blur\n",
    "        x0 = median_blur(image=x0)['image']\n",
    "    elif randomnr == 16:  # Apply Gaussian blur\n",
    "        x0 = gaussian_blur(image=x0)['image']\n",
    "    elif randomnr == 17:  # Apply pixel dropout\n",
    "        x0 = pixel_dropout(image=x0)['image']\n",
    "\n",
    "    return x0\n",
    "\n",
    "\n",
    "def save(model, prefix):\n",
    "    \"\"\"\n",
    "    Saves the model weights and architecture to files.\n",
    "\n",
    "    Args:\n",
    "        model (keras.Model): The model to save.\n",
    "        prefix (str): The file prefix for saving the model.\n",
    "    \"\"\"\n",
    "    # Save the model weights\n",
    "    model.save_weights(f\"{prefix}.h5\")\n",
    "\n",
    "    # Serialize the model architecture to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(f\"{prefix}.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "        \n",
    "def get_folder_count(folder):\n",
    "    file_count = sum(len(files) for _, _, files in os.walk(folder))\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Settings\n",
    "batch_size = 32  # Number of images per batch. Adjusted for high resolution (384x384px).\n",
    "nr_epochs = 1000  # Total number of training epochs\n",
    "img_width, img_height = 384, 384  # Image dimensions\n",
    "input_shape = (img_width, img_height, 3)  # Input shape for the model\n",
    "\n",
    "# Model and Dataset Information\n",
    "model_name = 'effinet_v1'  # Name of the model\n",
    "load_imagenet_weights = False  # Flag to determine if ImageNet weights should be loaded\n",
    "\n",
    "# Dataset Paths\n",
    "train_data_dir = '/trainset'  # Directory for training data\n",
    "validation_data_dir = '/valset'  # Directory for validation data\n",
    "\n",
    "# Retrieve Dataset Information\n",
    "nr_train_samples = get_folder_count(train_data_dir)\n",
    "nr_val_samples = get_folder_count(validation_data_dir)\n",
    "\n",
    "# Print Dataset Details\n",
    "print(\"Loading dataset:\")\n",
    "print(f\"Number of training samples: {nr_train_samples}\")\n",
    "print(f\"Number of validation samples: {nr_val_samples}\")\n",
    "\n",
    "# Class Information\n",
    "nr_classes = 2  # Number of classes\n",
    "tags = ['positive', 'negative']  # Class labels\n",
    "\n",
    "# Set TensorFlow Backend Image Data Format\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generators for Training and Validation\n",
    "\n",
    "# Training Data Generator with Augmentations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input_augment,  # Custom preprocessing function\n",
    "    brightness_range=[0.97, 1.03],  # Adjust brightness within the specified range\n",
    "    horizontal_flip=True,  # Random horizontal flip\n",
    "    vertical_flip=True  # Random vertical flip\n",
    ")\n",
    "\n",
    "# Validation/Test Data Generator without Augmentations\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# Training Data Generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,  # Path to training data\n",
    "    shuffle=True,  # Shuffle training data\n",
    "    target_size=(img_width, img_height),  # Resize images to specified dimensions\n",
    "    batch_size=batch_size,  # Batch size\n",
    "    class_mode='binary'  # Binary classification\n",
    ")\n",
    "\n",
    "# Validation Data Generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,  # Path to validation data\n",
    "    shuffle=True,  # Shuffle validation data\n",
    "    target_size=(img_width, img_height),  # Resize images to specified dimensions\n",
    "    batch_size=batch_size,  # Batch size\n",
    "    class_mode='binary'  # Binary classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, nb_classes=2):\n",
    "    \"\"\"\n",
    "    Builds a model with EfficientNetV2B2 as the base and custom head.\n",
    "    \n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input image.\n",
    "        nb_classes (int): Number of output classes. Default is 2.\n",
    "    \n",
    "    Returns:\n",
    "        model (keras.Model): Compiled model.\n",
    "    \"\"\"\n",
    "    # Initialize the base model\n",
    "    base_model = EfficientNetV2B2(weights=None, input_shape=input_shape, include_top=False)\n",
    "    \n",
    "    # Set base model layers as trainable\n",
    "    base_model.trainable = True\n",
    "\n",
    "    # Create the head of the model\n",
    "    head_model = base_model.output\n",
    "    head_model = GlobalAveragePooling2D()(head_model)\n",
    "    head_model = Dropout(0.2)(head_model)\n",
    "    output_layer = Dense(nb_classes-1, activation=\"sigmoid\")(head_model)\n",
    "\n",
    "    # Build the final model\n",
    "    model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNet model\n",
    "print(\"Loading Efficient model\")\n",
    "model = build_model(input_shape, nb_classes=2)\n",
    "\n",
    "# Define optimizer with configuration\n",
    "optimizer = SGD(learning_rate=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Compile the model with loss function and metrics\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        \"binary_accuracy\", \n",
    "        AUC(),\n",
    "        Precision(),\n",
    "        Recall(),\n",
    "        TruePositives(),\n",
    "        TrueNegatives(),\n",
    "        FalsePositives(),\n",
    "        FalseNegatives()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "print(\"Setting up callbacks...\")\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"effinet_epoch.{epoch:02d}.h5\",\n",
    "    save_weights_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    save_best_only=False\n",
    ")\n",
    "\n",
    "csv_logger = CSVLogger(f\"{model_name}_model_history_log.csv\", append=True)\n",
    "\n",
    "callbacks = [model_checkpoint_callback, csv_logger]\n",
    "\n",
    "# Start training\n",
    "print(\"Starting model training...\")\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    epochs=nr_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    steps_per_epoch=nr_train_samples // batch_size,\n",
    "    validation_steps=nr_val_samples // batch_size,\n",
    "    callbacks=callbacks,\n",
    "    workers=8,\n",
    "    max_queue_size=16,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "save(model, model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
